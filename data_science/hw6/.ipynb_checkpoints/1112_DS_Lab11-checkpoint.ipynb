{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Scikit-learn實作人工類神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介紹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cite Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class  <font size=\"3\" color=\"red\">MLPClassifier</font> implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.\n",
    "\n",
    "MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples), which holds the target values (class labels) for the training samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT\n",
    "<font size=\"3\" color=\"red\">from sklearn.neural_network import MLPClassifier</font> \n",
    "## CLASS\n",
    "```C\n",
    "MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "              activation=’relu’, \n",
    "              solver=’adam’, \n",
    "              alpha=0.0001, \n",
    "              batch_size=’auto’, \n",
    "              learning_rate=’constant’, \n",
    "              learning_rate_init=0.001, \n",
    "              power_t=0.5, \n",
    "              max_iter=200, \n",
    "              shuffle=True, \n",
    "              random_state=None, \n",
    "              tol=0.0001, \n",
    "              verbose=False, \n",
    "              warm_start=False, \n",
    "              momentum=0.9, \n",
    "              nesterovs_momentum=True, \n",
    "              early_stopping=False, \n",
    "              validation_fraction=0.1, \n",
    "              beta_1=0.9, \n",
    "              beta_2=0.999, \n",
    "              epsilon=1e-08)\n",
    "```              \n",
    "```C              \n",
    "參數說明\n",
    "\n",
    "hidden_layer_sizes=(100, 2)  # 隱藏層的數量, 此範例是第一層100個nodes，第二層2個nodes\n",
    "default 100\n",
    "\n",
    "\n",
    "activation='relu'  # 激勵函數\n",
    "default relu {identity, logistic, tanh, relu}\n",
    "\n",
    "# identity, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "# logistic, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "# tanh, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "# relu, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "solver='adam' #  The solver for weight optimization(使 LOSS最小之最佳化方式).\n",
    "default adam {lbfgs, adam, sgd}\n",
    "\n",
    "# ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "# ‘sgd’ refers to stochastic gradient descent.\n",
    "# ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "# 建議小型的資料集使用L-BFGS (要計算Hessian逆矩阵)\n",
    "# 資料集\t方式\n",
    "#  小     lbfgs\n",
    "#  大\t adam/sgd\n",
    "\n",
    "alpha = 1e-05  #L2 penalty (regularization term) parameter( L2正規化參數，可降低過擬合的風險)\n",
    "default 0.0001\n",
    "\n",
    "batch_size  # Size of minibatches for stochastic optimizers\n",
    "default auto(200, n_samples)\n",
    "#如果solver是lbfgs，則不考慮\n",
    "    \n",
    "learning_rate='constant' #Learning rate schedule for weight updates (學習速率參數變化方式)\n",
    "default constant {constant, invscaling, adaptive}\n",
    "# Only used when solver=‘sgd’.\n",
    "# constant:依learning_rate_init之設定，不改變\n",
    "# invscaling:逐漸減小，effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "# adaptive:只要Cost function保持下降，那學習效率就會保持不變。但是當不能有效降低或當early_stopping=on，不能增加驗證分數的時候，那學習效率就會調整\n",
    "    \n",
    "learning_rate_init==0.001 #學習速率參數\n",
    "default 0.001\n",
    "# Only used when solver=’sgd’ or ‘adam’.\n",
    "\n",
    "power_t=0.5  #反縮放學習效率的指數，當learning_rate=invscaling時用來更新學習效率用。\n",
    "default 0.5\n",
    "# Only used when solver=’sgd’.\n",
    "\n",
    "max_iter=200  #最大迭代次數，看是先到tol還是先到max_iter。\n",
    "default 200\n",
    "\n",
    "\n",
    "shuffle #每次的迭次是否要亂數洗牌。\n",
    "default True {True, False}\n",
    "#Only used when solver=’sgd’ or ‘adam’.\n",
    "\n",
    "random_state=1 #隨機數種子\n",
    "default None\n",
    "\n",
    "tol  #Tolerance for the optimization.假如連續兩次的迭代無法降低成本函數，或是得分無法增加，除非learning_rate=‘adaptive’，不然就當做已經收斂完成而結束。\n",
    "default 0.0001\n",
    "\n",
    "verbose=0  #過程是否輸出\n",
    "default 0\n",
    "\n",
    "# 0 不輸出\n",
    "# 1 偶爾輸出\n",
    "# 2 一定輸出\n",
    "\n",
    "warm_start 如果你想做更多的監控來了解模型走向的話，就可以自己寫for來配合使用。\n",
    "default False {True, False}\n",
    "\n",
    "\n",
    "momentum  # Momentum for gradient descent update. 配合sgd的一個動量設置，(0-1)\n",
    "default 0.9\n",
    "\n",
    "nesterovs_momentum #nesterovs_momentum是momentum的一個改良。\n",
    "default True {True, False}\n",
    "\n",
    "#只用於sgd與momentum>0\n",
    "\n",
    "early_stopping\n",
    "default False {True, False}\n",
    "# 設置用於當驗證得分沒有改善的時候是否要提早結束。\n",
    "如果設置True的話，則會自動拿10%數據集來做驗證，當最後兩次的迭代都沒有改善的時候就會停止。\n",
    "# Only effective when solver=’sgd’ or ‘adam’\n",
    "\n",
    "validation_fraction  # 驗證數據比例，early_stopping=True的時候有效。\n",
    "default 0.1\n",
    "\n",
    "beta_1\n",
    "default 0.9(0-1)\n",
    "# Only used when solver=’adam’\n",
    "\n",
    "beta_2\n",
    "default 0.999(0-1)\n",
    "# Only used when solver=’adam’\n",
    "\n",
    "epsilon\n",
    "default 1e-8\n",
    "# Only used when solver=’adam’\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 簡單的範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2., 2.], [-2.,-2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP can fit a non-linear model to the training data. clf.coefs_ contains the weight matrices that constitute the model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (5, 2), (2, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[coef.shape for coef in clf.coefs_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14196276, -0.02104562, -0.85522848, -3.51355396, -0.60434709],\n",
       "       [-0.69744683, -0.9347486 , -0.26422217, -3.35199017,  0.06640954]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29164405, -0.14147894],\n",
       "       [ 2.39665167, -0.6152434 ],\n",
       "       [-0.51650256,  0.51452834],\n",
       "       [ 4.0186541 , -0.31920293],\n",
       "       [ 0.32903482,  0.64394475]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.53025854],\n",
       "       [-0.86285329]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coefs_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.96718015e-004, 9.99803282e-001],\n",
       "       [1.00000000e+000, 2.80288501e-171]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[2., 2.], [-2., -2.]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLPClassifier supports multi-class classification by applying Softmax as the output function.\n",
    "\n",
    "Further, the model supports multi-label classification in which a sample can belong to more than one class. For each class, the raw output passes through the logistic function. Values larger or equal to 0.5 are rounded to 1, otherwise to 0. For a predicted output of a sample, the indices where the value is 1 represents the assigned classes of that sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [[0, 1], [1, 1]]\n",
    "clf = MLPClassifier(solver='lbfgs', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(15, ), \n",
    "                    random_state=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用ANN預測股市漲跌\n",
    "讀入上一次處理好的股市漲跌資料來進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>^TWII</th>\n",
       "      <th>^AORD</th>\n",
       "      <th>^AXJO</th>\n",
       "      <th>^BFX</th>\n",
       "      <th>^BSESN</th>\n",
       "      <th>^BUK100P</th>\n",
       "      <th>^BVSP</th>\n",
       "      <th>^DJI</th>\n",
       "      <th>^FCHI</th>\n",
       "      <th>...</th>\n",
       "      <th>^MXX</th>\n",
       "      <th>^N225</th>\n",
       "      <th>^NYA</th>\n",
       "      <th>^NZ50</th>\n",
       "      <th>^RUT</th>\n",
       "      <th>^STOXX50E</th>\n",
       "      <th>^TA125.TA</th>\n",
       "      <th>^XAX</th>\n",
       "      <th>000001.SS</th>\n",
       "      <th>IMOEX.ME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-04-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-04-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ^TWII  ^AORD  ^AXJO  ^BFX  ^BSESN  ^BUK100P  ^BVSP  ^DJI  \\\n",
       "0  2015-04-15    0.0    0.0    0.0   0.0     0.0       0.0    0.0   0.0   \n",
       "1  2015-04-27    1.0    1.0    1.0   0.0     0.0       0.0    1.0   1.0   \n",
       "2  2015-04-29    0.0    0.0    0.0   0.0     0.0       0.0    1.0   0.0   \n",
       "3  2015-05-06    0.0    0.0    0.0   0.0     0.0       0.0    1.0   1.0   \n",
       "4  2015-05-11    0.0    0.0    0.0   1.0     1.0       1.0    0.0   1.0   \n",
       "\n",
       "   ^FCHI  ...  ^MXX  ^N225  ^NYA  ^NZ50  ^RUT  ^STOXX50E  ^TA125.TA  ^XAX  \\\n",
       "0    0.0  ...   1.0    1.0   0.0    1.0   0.0        0.0        0.0   1.0   \n",
       "1    0.0  ...   0.0    1.0   1.0    0.0   0.0        0.0        0.0   1.0   \n",
       "2    0.0  ...   0.0    0.0   0.0    1.0   0.0        0.0        0.0   0.0   \n",
       "3    0.0  ...   1.0    0.0   0.0    0.0   1.0        0.0        0.0   0.0   \n",
       "4    1.0  ...   1.0    1.0   1.0    1.0   1.0        1.0        1.0   1.0   \n",
       "\n",
       "   000001.SS  IMOEX.ME  \n",
       "0        1.0       1.0  \n",
       "1        1.0       0.0  \n",
       "2        0.0       1.0  \n",
       "3        0.0       0.0  \n",
       "4        1.0       1.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market = pd.read_csv('market.csv')\n",
    "market.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    market.iloc[:, 2:], market['^TWII'], \n",
    "    train_size=0.8, \n",
    "    random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67819994\n",
      "Iteration 2, loss = 0.66690368\n",
      "Iteration 3, loss = 0.65170263\n",
      "Iteration 4, loss = 0.63698058\n",
      "Iteration 5, loss = 0.61959334\n",
      "Iteration 6, loss = 0.60526840\n",
      "Iteration 7, loss = 0.59336309\n",
      "Iteration 8, loss = 0.58504754\n",
      "Iteration 9, loss = 0.57799943\n",
      "Iteration 10, loss = 0.57284179\n",
      "Iteration 11, loss = 0.56872590\n",
      "Iteration 12, loss = 0.56472188\n",
      "Iteration 13, loss = 0.56818511\n",
      "Iteration 14, loss = 0.55847016\n",
      "Iteration 15, loss = 0.55556555\n",
      "Iteration 16, loss = 0.55986945\n",
      "Iteration 17, loss = 0.55402597\n",
      "Iteration 18, loss = 0.54808346\n",
      "Iteration 19, loss = 0.54577976\n",
      "Iteration 20, loss = 0.54305632\n",
      "Training set score: 0.736041\n",
      "Test set score: 0.636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=20, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "print(\"Training set score: %f\" % mlp.score(train_x, train_y))\n",
    "print(\"Test set score: %f\" % mlp.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改變感知機數量提高預測分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6565656565656566"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100, 100), \n",
    "                    max_iter=100000000,\n",
    "                    alpha=1e-4,\n",
    "                    solver='sgd', \n",
    "                    tol=1e-4, \n",
    "                    random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "mlp.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6767676767676768"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(1000, 500, 500, 500, 500), \n",
    "                    max_iter=100000000,\n",
    "                    alpha=1e-4,\n",
    "                    solver='sgd', \n",
    "                    tol=1e-4, \n",
    "                    random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "mlp.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7171717171717171"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 300, 300, 100, 300, 500), \n",
    "                    max_iter=100000000,\n",
    "                    alpha=1e-4,\n",
    "                    solver='sgd', \n",
    "                    tol=1e-4, \n",
    "                    random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "mlp.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 請嘗試改變 hidden layer, node number, learning rate, normalization, or changing activaton function to improve your ANN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(200, 300, 300, 100, 300, 500), \n",
    "                    max_iter=100000000,\n",
    "                    alpha=1e-4,\n",
    "                    solver='sgd', \n",
    "                    tol=1e-4, \n",
    "                    random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "mlp.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
